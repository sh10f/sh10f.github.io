---
layout: post
title: ML2025-HongyiLi-HW3-Understanding Transformer
date: 2025-04-04 16:00:00
summary: 
categories: ML2025-Hongyi_Li
---

* å®éªŒé‡‡ç”¨ Model å¦‚ä¸‹ï¼š
  * `google/gemma-2-2b-it`
  * ms-macro-MiniLM-L6-v2
* æœ‰è¶£çš„ç‚¹
  * <a href="#chat template">Why the Coherence Score with Chat Template is higher than Without templateï¼Ÿ</a>
  * 

# Problem 1 - Chat template Comparison (1pt) 

Task **Descriptions**: Observations of response with/without chat template. 

**Prompt**: â€œPlease tell me about the key differences between supervised learning and unsupervised learning. Answer in 200 words.â€ 

**Questions**: Calculate and compare the coherence score between responses generated with and without the chat template. 

## 1   What is each coherence score? 

* with chat template
  * ![image-20250403141840838](https://raw.githubusercontent.com/sh10f/images/master/img/image-20250403141840838.png)
  * Coherence Scoreï¼š 4.3467
* Without Chat Template
  * ![image-20250403141941632](https://raw.githubusercontent.com/sh10f/images/master/img/image-20250403141941632.png)
  * Coherence Scoreï¼š-3.9188



## 2. Which score is higher?

- the Score **with Chat Template** is **higher**



## 3 Why the Coherence Score with Chat Template is higher than Without templateï¼Ÿ

<a name="chat template">Â ğŸ¤”</a>

- æœ€å¼€å§‹æˆ‘ä»¥ä¸ºæ˜¯ **Prompt Engineer** å¯¼è‡´çš„åŒºåˆ«ï¼Œå³ æç¤ºè¯æœ€å¥½æ˜¯ç»“æ„åŒ–æ•°æ®

  - ä¾‹å¦‚

    ```python
    Prompt = """
    ### è§’è‰²é…ç½®ï¼šä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆ
    ### ä»»åŠ¡è¯´æ˜ï¼šè¯·ä½ ä½¿ç”¨Numpyå’ŒPandaså¯¹ç»™å®šæ•°æ®è¿›è¡Œåˆ†æ
    ### ç¤ºä¾‹ï¼š
    # ç¤ºä¾‹1ï¼šXXXX
    ### æ•°æ®å¦‚ä¸‹ï¼š
    # æ•°æ®ï¼š XXXXX
    ### æ ¼å¼è¦æ±‚ï¼š
    # è¯·ä½ è¾“å‡ºæ—¶åœ¨ â€œã€åˆ†æã€‘â€åé¢è¿›è¡Œ
    """
    ```

  - å®éªŒç»“æœä¸ºï¼š

    ![image-20250403163344701](https://raw.githubusercontent.com/sh10f/images/master/img/image-20250403163344701.png)

  - Coherence Scoreï¼š 2.57

  - é€šè¿‡å•çº¯æç¤ºè¯æ²¡æœ‰è¾¾åˆ°Chat Templateçš„æ•ˆæœï¼Œè¯´æ˜è¿˜æœ‰å…¶ä»–åŸå› 

- æŸ¥è¯¢huggingfaceæ–‡æ¡£([Chat Templates](https://huggingface.co/learn/nlp-course/chapter11/2?fw=pt)) å‘ç°æœ‰ Base Model å’Œ Instruct Model ä¹‹åˆ†

  - Base Model æ˜¯åœ¨åŸå§‹æ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒ
  - Instruct Modeæ˜¯ç»è¿‡å¾®è°ƒåçš„æ¨¡å‹ï¼ŒæŒ‡ä»¤è·Ÿéšçš„èƒ½åŠ›æ›´å¼ºã€‚ä½†æ˜¯è¿™ä¹Ÿè¦æ±‚äº†ä½¿ç”¨å¯¹åº”çš„Chat Templateï¼Œæ‰èƒ½æ¿€å‘LLMçš„èƒ½åŠ›

- Exampleï¼š `SmolLM2-135M-Instruct` çš„ chat Template configuration

  - ```jinja2
    "bos_token": "<|im_start|>",
    
    "chat_template": "
    {% for message in messages %}
        {% if loop.first and messages[0]['role'] != 'system' %}
            {{ '<|im_start|>system\nYou are a helpful AI assistant named SmolLM...<|im_end|>\n' }}
        {% endif %} // å¦‚æœå¯¹è¯ç¬¬ä¸€æ¡æ¶ˆæ¯ä¸æ˜¯ system è§’è‰²ï¼Œè‡ªåŠ¨æ’å…¥ä¸€æ¡é»˜è®¤æç¤º
        {{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}} // æ¯æ¡messageæŒ‰ç…§ä»¥ä¸Šæ ¼å¼è¿›è¡ŒåŒ…è£…
    {% endfor %}
    {% if add_generation_prompt %}
        {{ '<|im_start|>assistant\n' }} // åœ¨å¯¹è¯æœ«å°¾æ·»åŠ æ ‡è®°ï¼Œæç¤ºæ¨¡å‹å¼€å§‹ç”Ÿæˆå›å¤ã€‚
    {% endif %},
    
    "clean_up_tokenization_spaces": false,
    
    "eos_token": "<|im_end|>",
    ```

    

- æ›´æ¢  [gemma-2-2b-it](https://huggingface.co/google/gemma-2-2b-it/blob/main/tokenizer_config.json) å¯¹åº”æ¨¡æ¿åï¼š

  - ![image-20250403174534939](https://raw.githubusercontent.com/sh10f/images/master/img/image-20250403174534939.png)
  - Coherence Scoreï¼š7.22
  - è¿”å›çš„contentåŒ…å«äº†userçš„å†…å®¹ï¼Œä½†æ˜¯model contentå’Œä½¿ç”¨chat Templateçš„è¾“å‡ºä¸€è‡´

- **difference** between Chat Templates

  - **System Message handling**
    - ä¸åŒçš„æ¨¡å‹å¯¹ System Messageçš„å¤„ç†ä¸åŒ
    - ä¾‹å¦‚ `gemma-2-2b-it` ä¼šå°† `system`æ›¿æ¢ä¸º `model`
    - åŒ…å« `system` çš„ ***tag*** ä¸åŒã€‚ `Qwen`é‡‡ç”¨ `<|im_start|>`, `GPT` é‡‡ç”¨ `SYSTEM`
  - **Message Tag**

- ä¸ºäº† è‡ªé€‚åº”è¿™äº› ä¸åŒçš„ Chat Templates

  -  `transformer`åº“ä¸­ `AutoTokenizer.from_pretrained` ä¼šåŠ è½½ `chat_template`å±æ€§ã€‚
  - åé¢åœ¨ä½¿ç”¨ `tokenizer.apply_chat_template(messages, tokenize=False)`æ—¶è‡ªåŠ¨ä¿®æ”¹Messageã€‚

* ***Guidelines***

  * ä¸€è‡´çš„æ¨¡æ¿æ ¼å¼

  * æ¸…æ™°å®šä¹‰ Roleã€‚ å¸¸å¸¸åŒ…æ‹¬ `systemï¼Œuserï¼Œassistantï¼Œtool`

  * ä¸Šä¸‹æ–‡è®°å¿†ç®¡ç†ã€‚è­¦æƒ•è¶…å‡º Token Limits

  * Exampleï¼š

    * ```json
      messages = [
          {
              "role": "system",
              "content": "You are a helpful vision assistant that can analyze images.",
          },
          {
              "role": "user",
              "content": [
                  {"type": "text", "text": "What's in this image?"},
                  {"type": "image", "image_url": "https://example.com/image.jpg"},
              ],
          },
      ]
      ```

      



# Problem 2 - Multi-turn Conversations

Task **Descriptions**: Observe the response from the following multi-turn conversation. You should check the possibility of the model response and the format of the prompt inputted to the model. 



**Conversation History:** 

```python
{
    User (Your 1st Input): â€œName a color in a rainbow, please just answer in a word without any emoji.â€ 
    Model 1st output : xxxx. 
    
    User (Your 2nd Input): â€œThatâ€™s great! Now, could you tell me another color that I can find in a rainbow?â€ 
    Model 2nd output : xxxx. 
    
    User (Your 3rd Input): â€œCould you continue and name yet another color from the rainbow?â€ 
    Model 3rd output : xxxx. }
```



## 1  Provide the correct FULL prompt with chat template format for the third round.

```jinja2
<bos><start_of_turn>user
Name a color in a rainbow, please just answer in a word without any emoji.<end_of_turn>
<start_of_turn>model
Indigo<end_of_turn>
<start_of_turn>user
Thatâ€™s great! Now, could you tell me another color that I can find in a rainbow?<end_of_turn>
<start_of_turn>model
Orange<end_of_turn>
<start_of_turn>user
Could you continue and name yet another color from the rainbow?<end_of_turn>
<start_of_turn>model
```

* ç”±äº è¿‡å»è®°å¿† (round 1) çš„å­˜åœ¨ï¼Œå¯¼è‡´ Round 3 è¾“å‡ºä¹Ÿæ˜¯ ä¸€ä¸ªword
* 



## 2 What is the first token with the highest probability in the first round (question)?

![image-20250403191043056](https://raw.githubusercontent.com/sh10f/images/master/img/image-20250403191043056.png)

* ç¬¬ä¸€è½®çš„ç¬¬ä¸€ä¸ª Token æ˜¯ `<h1>`



## 3 How to check Tokens when generatintï¼Ÿ

```python
inputs = tokenizer(chat_template_format_prompt, return_tensors="pt").to("cuda")

# Get logits instead of directly generating
with torch.no_grad():
    outputs_p = model(**inputs)

logits = outputs_p.logits  # Logits of the model (raw scores before softmax)
print("logits shape: ", logits.shape)

last_token_logits = logits[:, 0, :]  # Take the logits of the first generated token (1, 5, 25600)

# Apply softmax to get probabilities  (1, 25600)
probs = torch.nn.functional.softmax(last_token_logits, dim=-1)
print("prob shape: ", probs.shape)

# Get top-k tokens (e.g., 10)
top_k = 10
top_probs, top_indices = torch.topk(probs, top_k)

# Convert to numpy for plotting
top_probs = top_probs.cpu().squeeze().numpy()
top_indices = top_indices.cpu().squeeze().numpy()
top_tokens = [tokenizer.decode([idx]) for idx in top_indices]
```





# Problem 3 - tokenization of a sentence

**Prompt**: "I love taking a Machine Learning course by Professor Hung-yi Lee, What about you?" 



## 1 How is the prompt being tokenized into?

**Fill-in-the-blank Questions**: How is the prompt being tokenized into? Please write the corresponding token index. 

<img src="https://raw.githubusercontent.com/sh10f/images/master/img/image-20250403192007150.png" alt="image-20250403192007150" style="zoom:50%;" />

```json
Token: <bos>, token index: 2

Token: I, token index: 235285

Token:  love, token index: 2182

Token:  taking, token index: 4998

Token:  a, token index: 476

Token:  Machine, token index: 13403

Token:  Learning, token index: 14715

Token:  course, token index: 3205

Token:  by, token index: 731

Token:  Professor, token index: 11325

Token:  Hung, token index: 18809

Token: -, token index: 235290

Token: yi, token index: 12636

Token:  Lee, token index: 9201

Token: ,, token index: 235269

Token:  What, token index: 2439

Token:  about, token index: 1105

Token:  you, token index: 692

Token: ?, token index: 235336
```



## 2. Tokenization

* *Word-based Tokenizer*

  * space
  * punctuation

  ç¦»æ•£è¡¨ç¤ºã€‚æ ¹æ®corpuså»ºç«‹è¯æ±‡è¡¨ï¼ŒåŠ ä¸Šä¸€ä¸ª `<UNKNOWN>` .

  ç¼ºç‚¹æ˜¯ ï¼š

  - è¯­ä¹‰ç›¸ä¼¼çš„è¯æ±‡ï¼Œåœ¨è¡¨ç¤ºä¸Šå´ä½“ç°ä¸å‡ºè¯­ä¹‰ç›¸ä¼¼ï¼Œå› ä¸ºæ˜¯ç¨€ç–one-hotå‘é‡ï¼Œå®ƒä»¬ä¸ç›¸ä¼¼
  - å‘é‡è¡¨ç¤º ç»´åº¦è¿‡å¤§
  - å¯¹äºä¸åœ¨è¯æ±‡è¡¨ä¸­è¯ï¼Œç»Ÿä¸€è¡¨ç¤ºä¸º `<UNKNOWN>`, ä¿¡æ¯ç¼ºå¤±å¾ˆå¤š

* *Character-based Tokenizer*

  * è¯æ±‡è¡¨å˜å°
  * Unknownå˜å°‘
  * ![image-20250403200329985](https://raw.githubusercontent.com/sh10f/images/master/img/image-20250403200329985.png)
  * ç¼ºç‚¹æ˜¯ï¼šä¸¢å¤±äº†éƒ¨åˆ†ä¿¡æ¯ï¼ŒCharacterä¸åƒwordä¸€æ ·æœ‰ä»·å€¼ã€‚ä¸åŒè¯­è¨€çš„Characterçš„è¯­ä¹‰å«é‡ä¸åŒ

* *Subword-based Tokenizer*

  * ç±»ä¼¼ å“ˆå¤«æ›¼æ ‘ï¼Œä½¿ç”¨é¢‘ç‡é«˜çš„è¯è¯­å•ç‹¬æ˜¯ä¸€ä¸ªTokenï¼Œ é¢‘ç‡ä½çš„è¯è¯­ä¼šåˆ†è§£æˆé¢‘ç‡é«˜çš„Token
  * ![image-20250403203233954](https://raw.githubusercontent.com/sh10f/images/master/img/image-20250403203233954.png)
  * ä¼˜ç‚¹æ˜¯ï¼š
    * æ›´å°çš„è¯æ±‡è¡¨ï¼Œåªéœ€è¦ ä½¿ç”¨é¢‘ç‡é«˜çš„Tokens
    * é™Œç”Ÿçš„è¯æ±‡å¯ä»¥æ‹†åˆ†æˆä½¿ç”¨é¢‘ç‡é«˜çš„è¯æ±‡

* ***Text To Sequence***

  * Text to Tokensï¼š

    * ```python
      sequence = "Using a Transformer network is simple"
      tokens = tokenizer.tokenize(sequence)
      # ['Using', 'a', 'transform', '##er', 'network', 'is', 'simple']
      ```

    * `Tokenize` å°†wordä¸æ–­åˆ†å‰²ï¼Œç›´åˆ°è¯æ±‡è¡¨èƒ½å¤Ÿè¡¨ç¤ºï¼Œè¿™ä¹Ÿé€ æˆäº† `transformer` è¢«åˆ†å‰²ä¸º `transform` å’Œ `##er`

  * Tokens to IDs

    * ```python
      ids = tokenizer.convert_tokens_to_ids(tokens)
      # [7993, 170, 11303, 1200, 2443, 1110, 3014]
      ```

  * IDs back to Text

    * ```python
      decoded_string = tokenizer.decode([7993, 170, 11303, 1200, 2443, 1110, 3014])
      # 'Using a Transformer network is simple'
      ```

    * `decode` æ–¹æ³•ä¸ä»…å°† IDs è½¬æ¢ä¸º Tokensï¼Œ è¿˜å°†åŒä¸€ä¸ªwordçš„Tokensç»„åˆä¸ºä¸€ä¸ªWord


## Summary of Tokenization

* LLMçš„è¾“å…¥æ˜¯ç¦»æ•£çš„IDsåºåˆ—
* Text To IDsåºåˆ— éœ€è¦ **ä¸¤æ­¥**
  * Text To Tokens
  * Tokens To IDs
* ä¸ºä»€ä¹ˆæˆ‘ä»¬ä½¿ç”¨Pre-Embeddingçš„ç»“æœä½œä¸ºLLMçš„è¾“å…¥ï¼Œè¿™æ˜¯å› ä¸º
  * LLMåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ Embedding çš„æƒé‡æ˜¯éšç€è®­ç»ƒæ›´æ–°çš„ï¼Œè¿™æ ·Embedding æ›´åŠ é€‚é…è®­ç»ƒä»»åŠ¡å’Œæ•°æ®ï¼Œä¸ä¼šå›ºå®š




# Problem 4 - Autoregressive Generation



Task **Descriptions**: 

*  Use auto-regressive generation to generate a sentence 20 times. 

* Calculate the **self-BLEU** score for the 20 sentences. 

- Compare Top-k sampling (k=2) vs. Top-k sampling (k=200) 

- Compare Top-p sampling (p=0.6) vs Top-p sampling (p=0.999) 

- Observe fluency, coherence, and diversity.

  

**Prompt**: "Generate a paraphrase of the sentence 'Professor Lee is one of the best 
teachers in the domain of machine learning'. Just response with one sentence."



## 1 What about self-BLEU score? 

* **Self-BLEU** åŸºäº **BLEU** (BiLingual Evaluation Understudy)
  * Self-BLEU æ˜¯ç”Ÿæˆæ ·æœ¬é›†ä¸­æ¯ä¸ªæ ·æœ¬é’ˆå¯¹å…¶ä½™ç”Ÿæˆæ ·æœ¬çš„ BLEU å¹³å‡
  * Self-BLEUæ˜¯æµ‹é‡ ç”Ÿæˆæ ·æœ¬é›†çš„å¤šæ ·æ€§(diversity)çš„ã€‚Self-BLEUè¶Šå°ï¼Œå¤šæ ·æ€§è¶Šå¥½
* **BLEU** åŸºäº **n-gram**
  * BLEU æ˜¯ ä¸¤ä¸ªæ ·æœ¬çš„1-gram åˆ° n-gram ä¸­ åŒ¹é…æ¦‚ç‡çš„ å‡ ä½•å¹³å‡
  * BLEU æ˜¯æµ‹é‡ ä¸¤ä¸ªæ ·æœ¬çš„ç›¸ä¼¼åº¦çš„ã€‚NLEUè¶Šå¤§ï¼Œç›¸ä¼¼åº¦è¶Šå¤§



## 2 What about top-p and top-k?

*  **Top-Kï¼ŒTop-P**æ˜¯ä¸åŒçš„éšæœºé‡‡æ ·ç­–ç•¥ã€‚è¿˜å¯ä»¥é€šè¿‡ **Temperature** æœºåˆ¶è°ƒèŠ‚æ¦‚ç‡åˆ†å¸ƒ

* Top-Kæ˜¯åœ¨å‰ K ä¸ªæ¦‚ç‡æœ€å¤§çš„æ ·æœ¬ä¸­è¿›è¡Œ Softmaxã€‚å³åœ¨è¿™ å‰ K ä¸ª æ ·æœ¬ä¸­é‡‡æ ·

  * ä¼˜ç‚¹ï¼šéšæœºé‡‡æ ·
  * ç¼ºç‚¹ï¼š
    * å›ºå®šå€™é€‰é›†ï¼Œä¸ªæ•°ä¸ºK
    * å—åˆ°æ ·æœ¬æ¦‚ç‡åˆ†å¸ƒçš„å½±å“è¾ƒå¤§ã€‚è‹¥å€™é€‰è¯æ–¹å·®è¾ƒå¤§ï¼Œå¯ä»¥é‡‡æ ·åˆ°æ¦‚ç‡æå°çš„å€™é€‰è¯ï¼Œå¯¼è‡´"èƒ¡è¨€ä¹±è¯­"ã€‚è‹¥æ–¹å·®å‡åŒ€ï¼Œåˆ™é‡‡æ ·åˆ°çš„éƒ½æ˜¯æ¦‚ç‡ç›¸è¿‘çš„å€™é€‰ï¼Œå¤šæ ·æ€§è¾ƒå·®

* Top-P æ˜¯åœ¨æ¦‚ç‡ä¹‹å’Œ **å¤§äº** Pçš„æ ·æœ¬é›†åˆä¸­é‡‡æ ·

  * å€™é€‰é›†æ•°é‡ä¸å›ºå®šã€‚
  * ä¸€å®šç¨‹åº¦é¿å…æ¦‚ç‡åˆ†å¸ƒçš„å½±å“ã€‚æ–¹å·®è¾ƒå¤§ï¼Œå¯èƒ½æ¦‚ç‡å¤§çš„å€™é€‰è¯çš„æ¦‚ç‡å’Œå°±è¶…è¿‡äº†Pï¼Œè¿™æ ·å°±é¿å…äº†é€‰æ‹©æ¦‚ç‡æå°çš„å€™é€‰ï¼Œä¸ä¼šèƒ¡è¨€ä¹±è¯­ã€‚å‡åŒ€åˆ†å¸ƒæ—¶ï¼Œä¹Ÿä¼šæ›´å¤šçš„å®¹çº³å€™é€‰è¯ï¼Œå¢åŠ å¤šæ ·æ€§

* Temperature æœºåˆ¶å°±æ˜¯åœ¨è®¡ç®—Softmaxä¹‹å‰ï¼Œæ‰€æœ‰æ ·æœ¬å…ˆé™¤ä»¥ä¸€ä¸ªTemperature

  * $$
    p\left(w_{i+1}^{1}, \ldots, w_{i+1}^{K}\right)=\left\{\frac{\exp \left(\frac{o_{i}\left[w_{i+1}^{1}\right]}{T}\right)}{\sum_{j=1}^{K} \exp \left(\frac{o_{i}\left[w_{i+1}^{j}\right]}{T}\right)}, \ldots, \frac{\exp \left(\frac{o_{i}\left[w_{i+1}^{K}\right]}{T}\right)}{\sum_{j=1}^{K} \exp \left(\frac{o_{i}\left[w_{i+1}^{j}\right]}{T}\right)}\right\}
    $$

  * Temperature ä¸€èˆ¬é»˜è®¤ä¸º 1.

  * è‹¥ Temperature > 1ï¼Œä¼šç¼©å°æ¦‚ç‡ä¹‹é—´çš„å·®è·ï¼Œå¢å¤§äº†ä¹‹å‰æ¦‚ç‡å°çš„æ ·æœ¬çš„è¢«é‡‡æ ·åˆ°çš„æœºä¼šï¼Œå¢å¤§äº†æ ·æœ¬å¤šæ ·æ€§

  * è‹¥ Temperature < 1, ä¼šå¢å¤§æ¦‚ç‡ä¹‹é—´çš„å·®è·ï¼Œå¤šæ ·æ€§å‡å°

## 3 What is the generated sentence of top-k for k = 1?

* **All identical !!**
* ![image-20250404113615724](https://raw.githubusercontent.com/sh10f/images/master/img/image-20250404113615724.png)

## 4 What is the generated sentence of top-p for p = 0?

* **All identical !!**
* å› ä¸ºç¬¬ä¸€ä¸ªæ ·æœ¬çš„æ¦‚ç‡ ä¸€å®šå¤§äº P=0. æ‰€ä»¥æ°¸è¿œåªä¼šé‡‡æ ·ç¬¬ä¸€ä¸ªæ ·æœ¬
* ![image-20250404113720611](https://raw.githubusercontent.com/sh10f/images/master/img/image-20250404113720611.png)

## 5 Compare the self-BLEU score of top-k for different k values ( 2 vs 200 ), which is higher and why? 



* |           | K=2    | K=20   |
  | :-------: | ------ | ------ |
  | Self-BLEU | 0.2704 | 0.0599 |
  |           |        |        |

## 6 Compare the self-BLEU score of top-p for different p values ( 0.6 vs 0.999 )? 



* |           | P=0.6  | P = 0.999 |
  | :-------: | ------ | --------- |
  | Self-BLEU | 0.5963 | 0.0952    |
  |           |        |           |






# Problem 5 - t-SNE 

Task **Descriptions**: Plotting the t-SNE 2-D Embeddings 

**Sentences**: (Provided in sample code) 

* "I ate a fresh apple.", # Apple (fruit) 
* "Apple released the new iPhone.", # Apple (company) 
* "I peeled an orange and ate it.", # Orange (fruit) 
* "The Orange network has great coverage.", # Orange (telecom) 
* "Microsoft announced a new update.", # Microsoft (company) 
* "Banana is my favorite fruit.", # Banana (fruit)



<img src="https://raw.githubusercontent.com/sh10f/images/master/img/image-20250404135734111.png" alt="image-20250404135734111" style="zoom: 67%;" />





# Problem 6 - Attention Map

Task **Descriptions**: Plot and observe the figure of the attention map 

**Prompt**: â€œGoogle â€

 Generated **tokens**: 20 

**Layer** index (Recommended): 10 

**Head** index (Recommended): 7

<img src="https://raw.githubusercontent.com/sh10f/images/master/img/image-20250404190151064.png" alt="image-20250404190151064" style="zoom:67%;" />
